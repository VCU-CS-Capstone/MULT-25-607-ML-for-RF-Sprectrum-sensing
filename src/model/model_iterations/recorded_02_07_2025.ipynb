{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "sys.path.append(\"../\")\n",
    "import h5py\n",
    "from MLRF.Networks import DSCNN, BasicCNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# -------------------------------------------------------------------\n",
    "# Weight Initialization Function\n",
    "# -------------------------------------------------------------------\n",
    "def init_weights(m):\n",
    "    \"\"\"\n",
    "    Initialize convolutional and linear layers using Kaiming normal initialization.\n",
    "    \"\"\"\n",
    "    if isinstance(m, (nn.Conv1d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Training Function with Gradient Clipping\n",
    "# -------------------------------------------------------------------\n",
    "def train(dataloader, model, loss_fn, optimizer, scaler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    batch_losses = []\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=\"Training\", unit=\"batch\", leave=False)\n",
    "    for sample, label in pbar:\n",
    "        sample = sample.to(device, non_blocking=True)\n",
    "        label = label.to(device, non_blocking=True)\n",
    "        \n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            pred = model(sample)\n",
    "            loss = loss_fn(pred, label)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        batch_loss = loss.detach().cpu().item()\n",
    "        total_loss += batch_loss * sample.size(0)\n",
    "        batch_losses.append(batch_loss)\n",
    "        pbar.set_postfix(loss=batch_loss)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset), batch_losses\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Testing Function\n",
    "# -------------------------------------------------------------------\n",
    "def test(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    batch_accuracies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc=\"Testing\", unit=\"batch\", leave=False)\n",
    "        for sample, label in pbar:\n",
    "            sample = sample.to(device, non_blocking=True)\n",
    "            label = label.to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                output = model(sample)\n",
    "                loss = loss_fn(output, label)\n",
    "                total_loss += loss.item() * sample.size(0)\n",
    "                \n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(label).sum().item()\n",
    "            batch_acc = 100 * pred.eq(label).float().mean().item()\n",
    "            batch_accuracies.append(batch_acc)\n",
    "            pbar.set_postfix(acc=batch_acc)\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader.dataset)\n",
    "    overall_acc = 100 * correct / len(dataloader.dataset)\n",
    "    return avg_loss, overall_acc, batch_accuracies\n",
    "\n",
    "class PSDDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            self.keys = list(f.keys())\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.file_path, 'r') as f:\n",
    "            key = self.keys[idx]\n",
    "            data = torch.tensor(f[key][:], dtype=torch.float32)\n",
    "            # Label: 0 if key starts with 'wifi', otherwise 1 (assumes BT keys don't start with 'wifi')\n",
    "            label = 0 if key.startswith('wifi') else 1\n",
    "        return data.unsqueeze(0), label  # Add channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc880f127d44b81b52d79e29eb2291e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/351 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ee19c33f5243389899eb1e5df31f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/46 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: Train Loss: nan, Test Loss: nan, Test Acc: 44.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b672560852224a7f991cefbc225d3a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/351 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9b5c4ef96f47bb901c5a2c0de6bffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/46 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: Train Loss: nan, Test Loss: nan, Test Acc: 44.85%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2722ba42aff4a3db02265a2e2c14dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/351 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66e664ddac44e2c910a1bf89f273153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/46 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: Train Loss: nan, Test Loss: nan, Test Acc: 44.85%\n",
      "Best accuracy: 44.85%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameters\n",
    "config = {\n",
    "    'batch_size': 512,\n",
    "    'epochs': 3,\n",
    "    'lr': 1e-4,\n",
    "    'patience': 5,\n",
    "    'model_path': 'best_model.pth'\n",
    "}\n",
    "\n",
    "# Dataset and DataLoader with optimized settings\n",
    "train_dataset = PSDDataset(\"/home/kush/projects/MULT-25-607-ML-for-RF-Sprectrum-sensing/src/model/data/finished/train_abs.hdf5\")\n",
    "test_dataset = PSDDataset(\"/home/kush/projects/MULT-25-607-ML-for-RF-Sprectrum-sensing/src/model/data/finished/test_abs.hdf5\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=config['batch_size']*2,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Model setup\n",
    "model = BasicCNN().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=1e-4)\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=3)\n",
    "\n",
    "best_acc = 0\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(config['epochs']):\n",
    "    train_loss, _ = train(train_loader, model, loss_fn, optimizer, scaler)\n",
    "    test_loss, test_acc, _ = test(test_loader, model, loss_fn)\n",
    "    scheduler.step(test_acc)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), config['model_path'])\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    # Early stopping\n",
    "    if patience_counter >= config['patience']:\n",
    "        print(f\"Early stopping at epoch {epoch}\")\n",
    "        break\n",
    "        \n",
    "    print(f\"Epoch {epoch+1}/{config['epochs']}: \"\n",
    "            f\"Train Loss: {train_loss:.4f}, \"\n",
    "            f\"Test Loss: {test_loss:.4f}, \"\n",
    "            f\"Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "print(f\"Best accuracy: {best_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"train\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "plt.gca().yaxis.set_major_locator(plt.MultipleLocator(0.025))\n",
    "plt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(accuracies, label=\"accuracy\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=1)\n",
    "ymin, ymax = min(accuracies), max(accuracies)\n",
    "if ymax > ymin:\n",
    "    plt.gca().yaxis.set_major_locator(plt.MultipleLocator((ymax - ymin)/4))\n",
    "else:\n",
    "    plt.gca().yaxis.set_major_locator(plt.MultipleLocator(0.25))\n",
    "plt.gca().xaxis.set_major_locator(plt.MultipleLocator(1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
